For the scanner, I implemented a vector and added every token to the vector in the order that they were received. If there was any character scanned that wasn't a part of the language, a scanner error was thrown immediately. This scanner read from stdin until there was no more input (EOF). For this part, I struggled with tokenizing nums that were larger than one digit (for example, 15 or 265). At first, my scanner would tokenize two-digit numbers as 'numnum' instead of 'num', and would tokenize 3-digit numbers as 'numnumnum' and so on. To fix this problem, I wrote a function that deleted a 'num' token if there were consecutive 'num' tokens within the vector.

For the grammar portion, I first modified it such that it was unambiguous. Then, I modified it once more to make it LL(1), and verified once again that it remained unambiguous after this modification. To turn this grammar into C++ code was fairly simple. For every non-terminal in the grammar, I created a function corresponding to that non-terminal. Then, within those functions, I translated the productions within the grammars to code. If a production produced terminals, then I would call eat_token(terminal), where 'terminal' was the next expected token. If a production produced more non-terminals, then the functions corresponding to those non-terminals were called, beginning the recursive descent process. At first, I was confused on how to represent epsilon productions, but then decided that I just needed to break out of the function if an epsilon production was supposed to be taken. Sometimes it seems difficult to make your code do 'nothing'.
